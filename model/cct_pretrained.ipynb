{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebfd7085",
   "metadata": {},
   "source": [
    "# CCT model\n",
    "\n",
    "## Overview\n",
    "\n",
    "* Using a pretrained model that is from this repo: https://github.com/SHI-Labs/Compact-Transformers \n",
    "* Copied the cct main python file and the utils because it is not in a form of package that we can just import \n",
    "* Curretntly using cct model with pretrained imagenet\n",
    "\n",
    "## Model choice\n",
    "* cct_14_7x2_224\n",
    "* cct_14_7x2_384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb121c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: timm in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (1.0.24)\n",
      "Requirement already satisfied: torchvision in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (0.25.0)\n",
      "Requirement already satisfied: pandas in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: pillow in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (12.1.0)\n",
      "Requirement already satisfied: torch in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from timm) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from timm) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from timm) (1.4.1)\n",
      "Requirement already satisfied: safetensors in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from timm) (0.7.0)\n",
      "Requirement already satisfied: numpy in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from torchvision) (2.4.2)\n",
      "Requirement already satisfied: filelock in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from torch->timm) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from torch->timm) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from torch->timm) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from torch->timm) (2026.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from huggingface_hub->timm) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from huggingface_hub->timm) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from huggingface_hub->timm) (25.0)\n",
      "Requirement already satisfied: shellingham in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from huggingface_hub->timm) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from huggingface_hub->timm) (4.67.3)\n",
      "Requirement already satisfied: typer-slim in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from huggingface_hub->timm) (0.21.1)\n",
      "Requirement already satisfied: anyio in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm) (0.16.0)\n",
      "Requirement already satisfied: colorama in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from jinja2->torch->timm) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages (from typer-slim->huggingface_hub->timm) (8.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 26.0 -> 26.0.1\n",
      "[notice] To update, run: c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install timm torchvision pandas pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "924312de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62aa82b",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad97ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, df, repo_root, img_size=224, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.repo_root = Path(repo_root)\n",
    "\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]\n",
    "                )\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img_path = self.repo_root / row[\"filepath_rel\"]\n",
    "        if not img_path.exists():\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "\n",
    "        label = int(row[\"canonical_id\"])\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a61835e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "tensor([ 4, 14, 25, 10, 23,  7,  0, 17,  0, 25])\n"
     ]
    }
   ],
   "source": [
    "repo_root = Path.cwd().parent\n",
    "splits_dir = repo_root / \"data\" / \"splits\"\n",
    "\n",
    "\n",
    "train_csv = pd.read_csv(splits_dir / \"pv_train.csv\")\n",
    "val_csv   = pd.read_csv(splits_dir / \"pv_val.csv\")\n",
    "test_csv  = pd.read_csv(splits_dir / \"pv_test.csv\")  \n",
    "\n",
    "train_dataset = PlantDataset(train_csv, repo_root)\n",
    "val_dataset   = PlantDataset(val_csv, repo_root)\n",
    "test_dataset  = PlantDataset(test_csv, repo_root)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Quick sanity check\n",
    "imgs, labels = next(iter(train_loader))\n",
    "print(imgs.shape) \n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954dd5f",
   "metadata": {},
   "source": [
    "# setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3ca1ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcad4bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jessl\\SMU (Master)\\computer_vision\\.venv\\Lib\\site-packages\\timm\\models\\registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "Removing classifier.fc.weight, number of classes has changed.\n",
      "Removing classifier.fc.bias, number of classes has changed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.conv_layers.0.0.weight\n",
      "tokenizer.conv_layers.1.0.weight\n",
      "classifier.positional_emb\n",
      "classifier.attention_pool.weight\n",
      "classifier.attention_pool.bias\n",
      "classifier.blocks.0.pre_norm.weight\n",
      "classifier.blocks.0.pre_norm.bias\n",
      "classifier.blocks.0.self_attn.qkv.weight\n",
      "classifier.blocks.0.self_attn.proj.weight\n",
      "classifier.blocks.0.self_attn.proj.bias\n",
      "classifier.blocks.0.linear1.weight\n",
      "classifier.blocks.0.linear1.bias\n",
      "classifier.blocks.0.norm1.weight\n",
      "classifier.blocks.0.norm1.bias\n",
      "classifier.blocks.0.linear2.weight\n",
      "classifier.blocks.0.linear2.bias\n",
      "classifier.blocks.1.pre_norm.weight\n",
      "classifier.blocks.1.pre_norm.bias\n",
      "classifier.blocks.1.self_attn.qkv.weight\n",
      "classifier.blocks.1.self_attn.proj.weight\n",
      "classifier.blocks.1.self_attn.proj.bias\n",
      "classifier.blocks.1.linear1.weight\n",
      "classifier.blocks.1.linear1.bias\n",
      "classifier.blocks.1.norm1.weight\n",
      "classifier.blocks.1.norm1.bias\n",
      "classifier.blocks.1.linear2.weight\n",
      "classifier.blocks.1.linear2.bias\n",
      "classifier.blocks.2.pre_norm.weight\n",
      "classifier.blocks.2.pre_norm.bias\n",
      "classifier.blocks.2.self_attn.qkv.weight\n",
      "classifier.blocks.2.self_attn.proj.weight\n",
      "classifier.blocks.2.self_attn.proj.bias\n",
      "classifier.blocks.2.linear1.weight\n",
      "classifier.blocks.2.linear1.bias\n",
      "classifier.blocks.2.norm1.weight\n",
      "classifier.blocks.2.norm1.bias\n",
      "classifier.blocks.2.linear2.weight\n",
      "classifier.blocks.2.linear2.bias\n",
      "classifier.blocks.3.pre_norm.weight\n",
      "classifier.blocks.3.pre_norm.bias\n",
      "classifier.blocks.3.self_attn.qkv.weight\n",
      "classifier.blocks.3.self_attn.proj.weight\n",
      "classifier.blocks.3.self_attn.proj.bias\n",
      "classifier.blocks.3.linear1.weight\n",
      "classifier.blocks.3.linear1.bias\n",
      "classifier.blocks.3.norm1.weight\n",
      "classifier.blocks.3.norm1.bias\n",
      "classifier.blocks.3.linear2.weight\n",
      "classifier.blocks.3.linear2.bias\n",
      "classifier.blocks.4.pre_norm.weight\n",
      "classifier.blocks.4.pre_norm.bias\n",
      "classifier.blocks.4.self_attn.qkv.weight\n",
      "classifier.blocks.4.self_attn.proj.weight\n",
      "classifier.blocks.4.self_attn.proj.bias\n",
      "classifier.blocks.4.linear1.weight\n",
      "classifier.blocks.4.linear1.bias\n",
      "classifier.blocks.4.norm1.weight\n",
      "classifier.blocks.4.norm1.bias\n",
      "classifier.blocks.4.linear2.weight\n",
      "classifier.blocks.4.linear2.bias\n",
      "classifier.blocks.5.pre_norm.weight\n",
      "classifier.blocks.5.pre_norm.bias\n",
      "classifier.blocks.5.self_attn.qkv.weight\n",
      "classifier.blocks.5.self_attn.proj.weight\n",
      "classifier.blocks.5.self_attn.proj.bias\n",
      "classifier.blocks.5.linear1.weight\n",
      "classifier.blocks.5.linear1.bias\n",
      "classifier.blocks.5.norm1.weight\n",
      "classifier.blocks.5.norm1.bias\n",
      "classifier.blocks.5.linear2.weight\n",
      "classifier.blocks.5.linear2.bias\n",
      "classifier.blocks.6.pre_norm.weight\n",
      "classifier.blocks.6.pre_norm.bias\n",
      "classifier.blocks.6.self_attn.qkv.weight\n",
      "classifier.blocks.6.self_attn.proj.weight\n",
      "classifier.blocks.6.self_attn.proj.bias\n",
      "classifier.blocks.6.linear1.weight\n",
      "classifier.blocks.6.linear1.bias\n",
      "classifier.blocks.6.norm1.weight\n",
      "classifier.blocks.6.norm1.bias\n",
      "classifier.blocks.6.linear2.weight\n",
      "classifier.blocks.6.linear2.bias\n",
      "classifier.blocks.7.pre_norm.weight\n",
      "classifier.blocks.7.pre_norm.bias\n",
      "classifier.blocks.7.self_attn.qkv.weight\n",
      "classifier.blocks.7.self_attn.proj.weight\n",
      "classifier.blocks.7.self_attn.proj.bias\n",
      "classifier.blocks.7.linear1.weight\n",
      "classifier.blocks.7.linear1.bias\n",
      "classifier.blocks.7.norm1.weight\n",
      "classifier.blocks.7.norm1.bias\n",
      "classifier.blocks.7.linear2.weight\n",
      "classifier.blocks.7.linear2.bias\n",
      "classifier.blocks.8.pre_norm.weight\n",
      "classifier.blocks.8.pre_norm.bias\n",
      "classifier.blocks.8.self_attn.qkv.weight\n",
      "classifier.blocks.8.self_attn.proj.weight\n",
      "classifier.blocks.8.self_attn.proj.bias\n",
      "classifier.blocks.8.linear1.weight\n",
      "classifier.blocks.8.linear1.bias\n",
      "classifier.blocks.8.norm1.weight\n",
      "classifier.blocks.8.norm1.bias\n",
      "classifier.blocks.8.linear2.weight\n",
      "classifier.blocks.8.linear2.bias\n",
      "classifier.blocks.9.pre_norm.weight\n",
      "classifier.blocks.9.pre_norm.bias\n",
      "classifier.blocks.9.self_attn.qkv.weight\n",
      "classifier.blocks.9.self_attn.proj.weight\n",
      "classifier.blocks.9.self_attn.proj.bias\n",
      "classifier.blocks.9.linear1.weight\n",
      "classifier.blocks.9.linear1.bias\n",
      "classifier.blocks.9.norm1.weight\n",
      "classifier.blocks.9.norm1.bias\n",
      "classifier.blocks.9.linear2.weight\n",
      "classifier.blocks.9.linear2.bias\n",
      "classifier.blocks.10.pre_norm.weight\n",
      "classifier.blocks.10.pre_norm.bias\n",
      "classifier.blocks.10.self_attn.qkv.weight\n",
      "classifier.blocks.10.self_attn.proj.weight\n",
      "classifier.blocks.10.self_attn.proj.bias\n",
      "classifier.blocks.10.linear1.weight\n",
      "classifier.blocks.10.linear1.bias\n",
      "classifier.blocks.10.norm1.weight\n",
      "classifier.blocks.10.norm1.bias\n",
      "classifier.blocks.10.linear2.weight\n",
      "classifier.blocks.10.linear2.bias\n",
      "classifier.blocks.11.pre_norm.weight\n",
      "classifier.blocks.11.pre_norm.bias\n",
      "classifier.blocks.11.self_attn.qkv.weight\n",
      "classifier.blocks.11.self_attn.proj.weight\n",
      "classifier.blocks.11.self_attn.proj.bias\n",
      "classifier.blocks.11.linear1.weight\n",
      "classifier.blocks.11.linear1.bias\n",
      "classifier.blocks.11.norm1.weight\n",
      "classifier.blocks.11.norm1.bias\n",
      "classifier.blocks.11.linear2.weight\n",
      "classifier.blocks.11.linear2.bias\n",
      "classifier.blocks.12.pre_norm.weight\n",
      "classifier.blocks.12.pre_norm.bias\n",
      "classifier.blocks.12.self_attn.qkv.weight\n",
      "classifier.blocks.12.self_attn.proj.weight\n",
      "classifier.blocks.12.self_attn.proj.bias\n",
      "classifier.blocks.12.linear1.weight\n",
      "classifier.blocks.12.linear1.bias\n",
      "classifier.blocks.12.norm1.weight\n",
      "classifier.blocks.12.norm1.bias\n",
      "classifier.blocks.12.linear2.weight\n",
      "classifier.blocks.12.linear2.bias\n",
      "classifier.blocks.13.pre_norm.weight\n",
      "classifier.blocks.13.pre_norm.bias\n",
      "classifier.blocks.13.self_attn.qkv.weight\n",
      "classifier.blocks.13.self_attn.proj.weight\n",
      "classifier.blocks.13.self_attn.proj.bias\n",
      "classifier.blocks.13.linear1.weight\n",
      "classifier.blocks.13.linear1.bias\n",
      "classifier.blocks.13.norm1.weight\n",
      "classifier.blocks.13.norm1.bias\n",
      "classifier.blocks.13.linear2.weight\n",
      "classifier.blocks.13.linear2.bias\n",
      "classifier.norm.weight\n",
      "classifier.norm.bias\n",
      "classifier.fc.weight\n",
      "classifier.fc.bias\n",
      "Trainable parameters: 163\n"
     ]
    }
   ],
   "source": [
    "from cct.cct import cct_14_7x2_224 \n",
    "\n",
    "# load pretrained\n",
    "model = cct_14_7x2_224(pretrained=True, progress=True, num_classes=26)  \n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "print(\"Trainable parameters:\", len(trainable_params))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc7ee40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 2\n"
     ]
    }
   ],
   "source": [
    "# freeze the whole layer other thant\n",
    "for name, param in model.named_parameters():\n",
    "    if \"classifier.fc\" in name:  \n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "\n",
    "print(\"Trainable parameters:\", len(trainable_params))  \n",
    "optimizer = torch.optim.Adam(trainable_params, lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16618797",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "ckpt_dir = repo_root / \"model\" / \"checkpoints\"\n",
    "ckpt_dir.mkdir(exist_ok=True)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "start_epoch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559dca3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b22cce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Loss: 1.4437, Train Acc: 0.6720 | Val Loss: 0.7728, Val Acc: 0.8419 BEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]:  41%|████▏     | 373/902 [1:12:47<28:25,  3.22s/it, acc=0.859, loss=0.733]     "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "\n",
    "    # TRAIN\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    train_loop = tqdm(\n",
    "        train_loader,\n",
    "        desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\",\n",
    "        leave=False\n",
    "    )\n",
    "\n",
    "    for imgs, labels in train_loop:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * imgs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        train_loop.set_postfix(\n",
    "            loss=train_loss / total,\n",
    "            acc=correct / total\n",
    "        )\n",
    "\n",
    "    train_loss /= total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    val_loop = tqdm(\n",
    "        val_loader,\n",
    "        desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\",\n",
    "        leave=False\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loop:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            val_loop.set_postfix(\n",
    "                loss=val_loss / total,\n",
    "                acc=correct / total\n",
    "            )\n",
    "\n",
    "    val_loss /= total\n",
    "    val_acc = correct / total\n",
    "\n",
    "    # CHECKPOINTING\n",
    "    is_best = val_acc > best_val_acc\n",
    "    if is_best:\n",
    "        best_val_acc = val_acc\n",
    "\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"val_acc\": val_acc\n",
    "    }\n",
    "\n",
    "    # Save latest\n",
    "    torch.save(checkpoint, ckpt_dir / \"last.pth\")\n",
    "\n",
    "    # Save best\n",
    "    if is_best:\n",
    "        torch.save(checkpoint, ckpt_dir / \"best.pth\")\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{EPOCHS}] \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} \"\n",
    "        f\"{'BEST' if is_best else ''}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2294755",
   "metadata": {},
   "source": [
    "# Test model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c7dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    return all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ba44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using test dataset\n",
    "y_true_pd, y_pred_pd = evaluate_model(model, test_loader, device)\n",
    "\n",
    "print(\"PlantDoc Test Results\")\n",
    "print(\"Accuracy :\", accuracy_score(y_true_pd, y_pred_pd))\n",
    "print(\"Precision:\", precision_score(y_true_pd, y_pred_pd, average=\"macro\"))\n",
    "print(\"Recall   :\", recall_score(y_true_pd, y_pred_pd, average=\"macro\"))\n",
    "print(\"F1       :\", f1_score(y_true_pd, y_pred_pd, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ab83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_root = Path.cwd().parent\n",
    "splits_dir = repo_root / \"data\" / \"splits\"\n",
    "\n",
    "\n",
    "plantdoc_test_csv = pd.read_csv(splits_dir / \"plantdoc_test_mapped.csv\")  \n",
    "\n",
    "plantdoc_test_dataset = PlantDataset(plantdoc_test_csv, repo_root)\n",
    "\n",
    "plantdoc_test_loader  = DataLoader(plantdoc_test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862af26a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m y_true_pd, y_pred_pd = evaluate_model(\u001b[43mmodel\u001b[49m, plantdoc_test_loader, device)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPlantDoc Test Results\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAccuracy :\u001b[39m\u001b[33m\"\u001b[39m, accuracy_score(y_true_pd, y_pred_pd))\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "y_true_pd, y_pred_pd = evaluate_model(model, plantdoc_test_loader, device)\n",
    "\n",
    "print(\"PlantDoc Test Results\")\n",
    "print(\"Accuracy :\", accuracy_score(y_true_pd, y_pred_pd))\n",
    "print(\"Precision:\", precision_score(y_true_pd, y_pred_pd, average=\"macro\"))\n",
    "print(\"Recall   :\", recall_score(y_true_pd, y_pred_pd, average=\"macro\"))\n",
    "print(\"F1       :\", f1_score(y_true_pd, y_pred_pd, average=\"macro\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
